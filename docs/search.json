[
  {
    "objectID": "publication.html",
    "href": "publication.html",
    "title": "Publications",
    "section": "",
    "text": "Peer Review Journal Article Publications\n\nEnos, J.Y., Amoako, R.D., Doku, I.K. (2021). Utilization, Predictors and Gaps in the Continuum of Care for Maternal and Newborn Health in Ghana (2021). International Journal of Maternal and Child Health and AIDS (IJMA), 10(1);98-108. https://doi.org/10.21106/ijma.425\nAmoako, R. D. ., Doku , I. K. ., & Enos , J. Y. . (2020). Predictors of Antenatal Care Utilization in the East Akim Municipality of Ghana. International Journal of Sciences: Basic and Applied Research (IJSBAR), 54(3), 42–58. Retrieved from https://www.gssrr.org/index.php/JournalOfBasicAndApplied/article/view/11826\n\n\n\nPublished Book Chapters\n\nAmoako, R. D. (2024). Discussion of Artificial Intelligence Innovations and Challenges for Paramedicine. IntechOpen. http://doi.org/10.5772/intechopen.115530\nEnos, J. Y., Amoako, R.D., Enos, S.K., Hayford, B. & Tette, M.E. “Perspective Chapter: Challenges to Postnatal Care in Sub-Saharan Africa – A Review” in Connell, T. (Ed.). (2024). Contemporary Challenges in Postnatal Care. Intech Open. http://doi.org/10.5772/intechopen.113846\n\n\n\nPreprints\n\nAmoako, R. D. Spatial Analysis of Fire Incidents and Urban Vulnerabilities in the Accra Metropolis of Ghana. https://www.researchsquare.com/article/rs-5285054/v1\n\n\n\nBlog Posts\n\nMy Journey in Writing a Bibliometric Analysis Paper (June 2025). In the MADBlog, ESM program, University of Tennessee, Knoxville. https://cehhs.utk.edu/elps/my-journey-in-writing-a-bibliometric-analysis-paper/\nFinding Your People: The Importance of Mentorship and Networking Early On (2024). In the MADBlog, ESM program, University of Tennessee, Knoxville. https://cehhs.utk.edu/elps/finding-your-people-the-importance-of-mentorship-and-networking-early-on/\nEvaluation in the era of Emerging Technologies. MAD with Methods and Measures (2023). In the MADBlog, ESM program. University of Tennessee, Knoxville. https://elps.utk.edu/2023/11/15/evaluation-in-the-age-of-emerging-technologies/\n\n\n\nManuscripts Under Review\n\nAmoako, R. D & Morrow, J. A. A Systematic Review of Instruments and Frameworks for Measuring Faculty AI Integration Knowledge, Attitudes, and Behaviors in Higher Education. Submitted to the International Journal of Artificial Intelligence in Education (IJAIED)\nAmoako, R. D. & Morrow, J. A. Development and Initial Validation of the Comprehensive AI Integration Readiness Survey. Submitted to the International Journal of Teaching and Learning in Higher Education (IJTLHE).\nAmoako, R. D. Towards a Culturally Responsive Evaluation Framework for Rural Appalachian School Mental Health Programs. Submitted to the Journal of Appalachian Studies.\nZahra, F.T., Amoako, R. D. Artificial Intelligence in Higher Education: A Systematic Review of Applications, Perceptions, and Ethical Considerations. Submitted to the International Journal of Artificial Intelligence in Education."
  },
  {
    "objectID": "projects/caiirs.html#project-overview",
    "href": "projects/caiirs.html#project-overview",
    "title": "CAIIRS",
    "section": "Project Overview",
    "text": "Project Overview"
  },
  {
    "objectID": "posts/welcome/index.html#abstract",
    "href": "posts/welcome/index.html#abstract",
    "title": "Eastern Evaluation Research Association (EERS, 2025 Conference)",
    "section": "Abstract:",
    "text": "Abstract:\nMental health programs aim to prevent or mitigate mental illness and promote psychological well-being. Evaluating the effectiveness of these programs is crucial, yet it presents unique challenges. This paper proposes a comprehensive culturally responsive evaluation (CCRE) framework specifically tailored to assessing school-based mental health programs in rural Appalachian communities. The Appalachian region of the United States faces significant challenges in addressing elevated rates of youth mental health issues, driven by socioeconomic disadvantages, limited access to care, and distinct cultural factors. While school mental health initiatives have emerged as a promising approach, rigorous evaluations are needed to examine their implementation, outcomes, and long-term community impacts through an Appalachian cultural lens. The proposed CCRE framework integrates core principles of cultural responsiveness with a nuanced understanding of Appalachian traditions, values, and knowledge systems. It provides structured yet flexible guidance across five stages: 1) Comprehensively analyzing the multi-layered community and sociopolitical contexts; 2) Collaboratively designing the evaluation with diverse local stakeholders to surface culturally-relevant priorities and indicators; 3) Implementing culturally-relevant, participatory inquiry methods and capacity building; 4) Engaging the community in collectively analyzing and contextualizing findings through an Appalachian worldview; and 5) Prioritizing local dissemination formats and translating insights into sustained community actions. By centralizing Appalachian voices, ways of knowing, and self-determination throughout the process, this framework aims to enhance evaluation validity, community buy-in, and long-term impacts on addressing mental health disparities. It presents a paradigm shift towards more ethical, equitable evaluations that authentically resonate within the distinct rural Appalachian cultural context.\nKeywords: Rural Appalachia, School Mental Health programs, Culturally Responsive Evaluation, Program Evaluation, Community engagement, Local knowledge systems"
  },
  {
    "objectID": "posts/elps-awards/elps.html",
    "href": "posts/elps-awards/elps.html",
    "title": "ELPS Awards-UTK",
    "section": "",
    "text": "I’m deeply honored to share that I received two awards at the 2025 Educational Leadership and Policy Studies (ELPS) Honors and Awards Ceremony:\n\nGraduate Student Research Excellence Award\nGraduate Student of the Year Award (Evaluation, Statistics and Methodology Program)\n\nThis recognition means so much to me, not just as milestones in my academic journey, but as affirmations of the collaborative effort behind my work. I’m grateful to my faculty advisors, colleagues, and the ELPS community for their unwavering support.\nA special thank you to Dr. Jennifer Ann Morrow and Dr. Louis Rocconi, whose guidance has been invaluable, and to my peers in the ESM program for fostering a space where rigorous scholarship and meaningful dialogue thrive."
  },
  {
    "objectID": "posts/elps-awards/elps.html#honored-with-two-elps-awards",
    "href": "posts/elps-awards/elps.html#honored-with-two-elps-awards",
    "title": "ELPS Awards-UTK",
    "section": "",
    "text": "I’m deeply honored to share that I received two awards at the 2025 Educational Leadership and Policy Studies (ELPS) Honors and Awards Ceremony:\n\nGraduate Student Research Excellence Award\nGraduate Student of the Year Award (Evaluation, Statistics and Methodology Program)\n\nThis recognition means so much to me, not just as milestones in my academic journey, but as affirmations of the collaborative effort behind my work. I’m grateful to my faculty advisors, colleagues, and the ELPS community for their unwavering support.\nA special thank you to Dr. Jennifer Ann Morrow and Dr. Louis Rocconi, whose guidance has been invaluable, and to my peers in the ESM program for fostering a space where rigorous scholarship and meaningful dialogue thrive."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "PhD Student | Researcher | Evaluator | AI Enthusiast | Data Scientist | Author\nEmail: ramoako@rd-amoako.com"
  },
  {
    "objectID": "index.html#richard-d.-amoako",
    "href": "index.html#richard-d.-amoako",
    "title": "Home",
    "section": "",
    "text": "PhD Student | Researcher | Evaluator | AI Enthusiast | Data Scientist | Author\nEmail: ramoako@rd-amoako.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me!",
    "section": "",
    "text": "I am excited to share my research, insights, and experiences in the fields of evaluation, education, health, and data science. My goal is to create a platform for discussion and collaboration among researchers, educators, and practitioners who are passionate about improving educational and health outcomes through data-driven approaches. I am Richard Dickson Amoako, a PhD student in the Department of Educational Leadership and Policy Studies at the University of Tennessee, Knoxville. I hold a Master of Public Health (MPH) and a Master of Science (MS) in Development Evaluation and Management. My research interests include educational evaluation, data visualization in evaluation, CRE frameworks and the application of artificial intelligence in education. I am passionate about using data to inform policy decisions and improve educational and health outcomes for all students. I have a strong background in quantitative research methods and statistical analysis, and I am skilled in using various data analysis tools and programming languages, including R, Python, and SQL. My work has focused on the integration AI into teaching and learning, evaluating educational programs and policies, and creating culturally responsible evaluation frameworks for rural Appalachian mental health programs. I have experience working with large datasets and conducting complex statistical analyses to identify trends and patterns in educational and health outcomes. I am also interested in the ethical implications of data use in education and the importance of equity and inclusion in educational research. I believe that data should be used to empower marginalized communities and promote social justice in education. I am excited to share my research and insights on this blog, and I hope to engage with others who are passionate about education, health and data science.\nPlease feel free to reach out to me through the links below or connect with me on social media. I look forward to hearing from you!"
  },
  {
    "objectID": "about.html#research-interests",
    "href": "about.html#research-interests",
    "title": "About Me!",
    "section": "Research Interests",
    "text": "Research Interests\nEvaluating educational programs and policies\nData science & data visualization\nArtificial intelligence in education\nIntegrating AI into teaching and learning\nMachine Learning (ML) and Natural Language Processing (NLP)\nCulturally responsible evaluation frameworks\nEthical implications of data use in education\nData-driven decision-making in education\nImproving educational and health outcomes for all students\nGeographic information systems (GIS) in education & Health\nMY CV"
  },
  {
    "objectID": "posts/aera-conferece/aera.html#abstract",
    "href": "posts/aera-conferece/aera.html#abstract",
    "title": "AERA Annual Meeting 2025, Denver",
    "section": "Abstract",
    "text": "Abstract\nArtificial Intelligence (AI) has emerged as a transformative force in higher education, enhancing learning experiences and optimizing administrative processes. However, integrating AI into teaching and learning practices remains underexplored, particularly concerning educators’ readiness and perceptions. This study aimed to develop and validate the Comprehensive AI Integration Readiness Survey (CAIIRS) to assess higher education educators’ readiness and willingness to integrate AI into their teaching, learning, and assessment practices. A nationwide survey was conducted among educators at public and private universities across the United States. The survey instrument, CAIIRS, was designed based on an extensive literature review and expert input. Data was collected online, and exploratory factor analysis (EFA) was used to determine the underlying factor structure. The EFA revealed three main factors: Integration and Effectiveness of AI in Teaching, Institutional Support for AI Integration, and Anxiety about AI Technology Use. The study found general recognition of AI’s benefits but highlighted significant anxiety among faculty and varying levels of institutional support. The findings underscore the need for comprehensive professional development and strong institutional support to facilitate effective AI integration. The CAIIRS scale provides a valuable tool for assessing faculty readiness and guiding targeted interventions, highlighting the complexities of adopting AI in higher education.\nKeywords: Generative Artificial Intelligence, Educators, Higher Education, Scale Development, Exploratory Factor Analysis, AI Integration\n\n\n\n\nWith My West African Colleagues at AERA 2025, Denver"
  },
  {
    "objectID": "posts/evie-2025/evie_2025.html",
    "href": "posts/evie-2025/evie_2025.html",
    "title": "EViE 6th Conference",
    "section": "",
    "text": "I had the privilege of presenting my research at the 6th EMERGENT VOICES IN EVALUATIION (EViE) Conference Virtually Hosted by the UNC Greensboro School of Education’s Educational Research Methodology Program. My presentation, titled “The Mediating Role of Anxiety in Faculty’s Integration of AI into Teaching Practices: Implications for Evaluation and Institutional Support,” explored the factors influencing higher education faculty’s readiness to integrate artificial intelligence (AI) into teaching and learning, focusing on the mediating role of anxiety about AI use. The study examines how institutional support, faculty characteristics, and anxiety contribute to AI integration, offering insights into how evaluators can assess and support AI adoption in educational settings.\nThis conference provided a platform for meaningful discussions on the intersection of evaluation, education, and technology. I am grateful to the organizers and participants for their insightful contributions and support."
  },
  {
    "objectID": "posts/evie-2025/evie_2025.html#presented-at-the-6th-evie-conference",
    "href": "posts/evie-2025/evie_2025.html#presented-at-the-6th-evie-conference",
    "title": "EViE 6th Conference",
    "section": "",
    "text": "I had the privilege of presenting my research at the 6th EMERGENT VOICES IN EVALUATIION (EViE) Conference Virtually Hosted by the UNC Greensboro School of Education’s Educational Research Methodology Program. My presentation, titled “The Mediating Role of Anxiety in Faculty’s Integration of AI into Teaching Practices: Implications for Evaluation and Institutional Support,” explored the factors influencing higher education faculty’s readiness to integrate artificial intelligence (AI) into teaching and learning, focusing on the mediating role of anxiety about AI use. The study examines how institutional support, faculty characteristics, and anxiety contribute to AI integration, offering insights into how evaluators can assess and support AI adoption in educational settings.\nThis conference provided a platform for meaningful discussions on the intersection of evaluation, education, and technology. I am grateful to the organizers and participants for their insightful contributions and support."
  },
  {
    "objectID": "projects/biblio_evalviz.html",
    "href": "projects/biblio_evalviz.html",
    "title": "Data Visualization and Communication in Evaluation",
    "section": "",
    "text": "In an era defined by unprecedented data volume, the ability to effectively visualize and communicate complex information has become critical across disciplines (Kirk, 2019). Within the field of evaluation, data visualization offers powerful tools for enhancing understanding, facilitating stakeholder engagement, and ultimately, informing better decisions (Few, 2012; Evergreen, 2017). As evaluation practice evolves to address increasingly complex social programs and policies, the strategic use of visual displays can transform raw data into actionable insights (Patton, 2018).\nDespite the growing recognition of data visualization’s potential, the field lacks a comprehensive synthesis of its development, key contributors, and emerging trends. Traditional literature reviews often fall short of capturing the breadth and interdisciplinary nature of this topic. Bibliometric analysis, a quantitative approach to mapping the structure of scientific knowledge, offers a rigorous and systematic alternative (Aria & Cuccurullo, 2017; van Eck & Waltman, 2014). By analyzing publication patterns, citation networks, and keyword co-occurrences, bibliometrics can reveal the intellectual landscape of data visualization in evaluation.\nThis study employs bibliometric methods using the PRISMA framework to address critical questions about data visualization evolution, key influences, thematic foci, and global distribution of research on data visualization within the evaluation field. Through a comprehensive analysis of scholarly publications, this research aims to provide a valuable resource for researchers, practitioners, and policymakers seeking to understand and leverage the power of data visualization to improve evaluation practice.\nResearch Questions: How has data visualization in evaluation evolved over time?"
  },
  {
    "objectID": "projects/biblio_evalviz.html#introduction",
    "href": "projects/biblio_evalviz.html#introduction",
    "title": "Data Visualization and Communication in Evaluation",
    "section": "",
    "text": "In an era defined by unprecedented data volume, the ability to effectively visualize and communicate complex information has become critical across disciplines (Kirk, 2019). Within the field of evaluation, data visualization offers powerful tools for enhancing understanding, facilitating stakeholder engagement, and ultimately, informing better decisions (Few, 2012; Evergreen, 2017). As evaluation practice evolves to address increasingly complex social programs and policies, the strategic use of visual displays can transform raw data into actionable insights (Patton, 2018).\nDespite the growing recognition of data visualization’s potential, the field lacks a comprehensive synthesis of its development, key contributors, and emerging trends. Traditional literature reviews often fall short of capturing the breadth and interdisciplinary nature of this topic. Bibliometric analysis, a quantitative approach to mapping the structure of scientific knowledge, offers a rigorous and systematic alternative (Aria & Cuccurullo, 2017; van Eck & Waltman, 2014). By analyzing publication patterns, citation networks, and keyword co-occurrences, bibliometrics can reveal the intellectual landscape of data visualization in evaluation.\nThis study employs bibliometric methods using the PRISMA framework to address critical questions about data visualization evolution, key influences, thematic foci, and global distribution of research on data visualization within the evaluation field. Through a comprehensive analysis of scholarly publications, this research aims to provide a valuable resource for researchers, practitioners, and policymakers seeking to understand and leverage the power of data visualization to improve evaluation practice.\nResearch Questions: How has data visualization in evaluation evolved over time?"
  },
  {
    "objectID": "projects/ccre.html#project-overview",
    "href": "projects/ccre.html#project-overview",
    "title": "CCRE",
    "section": "Project Overview",
    "text": "Project Overview"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "This project addresses the integration of artificial intelligence (AI) in higher education, focusing on the readiness and perceptions of faculty members regarding AI adoption in teaching, learning, and assessment. Recognizing that while AI is transforming higher education by enhancing learning experiences and streamlining administrative tasks, the practical integration of AI into instructional practices remains insufficiently explored, especially from the perspective of educators.\nThe primary objective was to develop and validate the Comprehensive AI Integration Readiness Survey (CAIIRS), a tool designed to measure faculty readiness for AI integration. The CAIIRS was constructed based on a thorough literature review and expert feedback, ensuring its relevance and comprehensiveness. Data were collected through a nationwide online survey targeting educators from both public and private universities and colleges across the United States.\nKeywords: Generative Artificial Intelligence, Educators, Higher Education, Scale Development, AI Integration\nMore Details\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn an era defined by unprecedented data volume, the ability to effectively visualize and communicate complex information has become critical across disciplines (Kirk, 2019). Within the field of evaluation, data visualization offers powerful tools for enhancing understanding, facilitating stakeholder engagement, and ultimately, informing better decisions (Few, 2012; Evergreen, 2017). As evaluation practice evolves to address increasingly complex social programs and policies, the strategic use of visual displays can transform raw data into actionable insights (Patton, 2018).\n\n\nThis study employs bibliometric methods using the PRISMA framework to address critical questions about data visualization evolution, key influences, thematic foci, and global distribution of research on data visualization within the evaluation field. Through a comprehensive analysis of scholarly publications, this research aims to provide a valuable resource for researchers, practitioners, and policymakers seeking to understand and leverage the power of data visualization to improve evaluation practice.\nMore Details\n\n\n\n\n\n\n\n\nThe Comprehensive Cultural Responsiveness Evaluation (CCRE) Framework is a structured approach designed to assess and enhance cultural responsiveness evaluation of mental health programs within the Appalachian region. This framework provides a systematic method for evaluating key dimensions of cultural responsiveness, including community perspective, collaborative design, socio-political dynamics, and community engagement. By identifying strengths and areas for improvement, CCRE serves as a diagnostic tool to guide educational and mental health institutions in their efforts to create inclusive and equitable learning environments that respect and celebrate diverse cultural perspectives.\nMore Details\n\n\n\n\n\n\n\nThe systematic review of instruments and frameworks for measuring faculty AI adoption readiness is a comprehensive analysis aimed at identifying and evaluating existing tools that assess the preparedness of educators for integrating artificial intelligence (AI) technologies in their teaching practices. This review seeks to synthesize current knowledge, highlight gaps in the literature, and provide recommendations for future research and development of more effective assessment instruments. By systematically reviewing the available literature, this project aims to contribute to a deeper understanding of faculty readiness for AI adoption and inform strategies for enhancing AI integration in educational settings.\nMore Details"
  },
  {
    "objectID": "projects.html#project-3-comprehensive-cultural-responsiveness-evaluation-ccre-framework",
    "href": "projects.html#project-3-comprehensive-cultural-responsiveness-evaluation-ccre-framework",
    "title": "My Projects",
    "section": "",
    "text": "The Comprehensive Cultural Responsiveness Evaluation (CCRE) Framework is a structured approach designed to assess and enhance cultural responsiveness evaluation of mental health programs within the Appalachian region. This framework provides a systematic method for evaluating key dimensions of cultural responsiveness, including community perspective, collaborative design, socio-political dynamics, and community engagement. By identifying strengths and areas for improvement, CCRE serves as a diagnostic tool to guide educational and mental health institutions in their efforts to create inclusive and equitable learning environments that respect and celebrate diverse cultural perspectives.\nMore Details"
  },
  {
    "objectID": "projects.html#project-4-review-of-instruments-and-frameworks-to-measuring-faculty-ai-integration-readiness",
    "href": "projects.html#project-4-review-of-instruments-and-frameworks-to-measuring-faculty-ai-integration-readiness",
    "title": "My Projects",
    "section": "",
    "text": "The systematic review of instruments and frameworks for measuring faculty AI adoption readiness is a comprehensive analysis aimed at identifying and evaluating existing tools that assess the preparedness of educators for integrating artificial intelligence (AI) technologies in their teaching practices. This review seeks to synthesize current knowledge, highlight gaps in the literature, and provide recommendations for future research and development of more effective assessment instruments. By systematically reviewing the available literature, this project aims to contribute to a deeper understanding of faculty readiness for AI adoption and inform strategies for enhancing AI integration in educational settings.\nMore Details"
  }
]